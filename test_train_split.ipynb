{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets transformers jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/klee12/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /users/klee12/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import interpreter_login\n",
    "\n",
    "interpreter_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "Downloading readme: 100%|██████████| 1.15k/1.15k [00:00<00:00, 5.39MB/s]\n",
      "Downloading data: 100%|██████████| 79.0M/79.0M [00:01<00:00, 45.7MB/s]\n",
      "Downloading data: 100%|██████████| 80.0M/80.0M [00:01<00:00, 61.9MB/s]\n",
      "Downloading data: 100%|██████████| 78.6M/78.6M [00:01<00:00, 52.2MB/s]\n",
      "Downloading data: 100%|██████████| 73.6M/73.6M [00:01<00:00, 50.6MB/s]\n",
      "Downloading data: 100%|██████████| 79.6M/79.6M [00:01<00:00, 51.6MB/s]\n",
      "Downloading data: 100%|██████████| 77.5M/77.5M [00:01<00:00, 53.4MB/s]\n",
      "Downloading data: 100%|██████████| 79.1M/79.1M [00:01<00:00, 57.7MB/s]\n",
      "Downloading data: 100%|██████████| 83.1M/83.1M [00:01<00:00, 58.4MB/s]\n",
      "Downloading data: 100%|██████████| 77.7M/77.7M [00:01<00:00, 52.6MB/s]\n",
      "Downloading data: 100%|██████████| 82.5M/82.5M [00:01<00:00, 55.0MB/s]\n",
      "Downloading data: 100%|██████████| 73.6M/73.6M [00:01<00:00, 54.8MB/s]\n",
      "Downloading data: 100%|██████████| 81.1M/81.1M [00:01<00:00, 49.6MB/s]\n",
      "Downloading data: 100%|██████████| 77.6M/77.6M [00:01<00:00, 59.3MB/s]\n",
      "Downloading data: 100%|██████████| 74.0M/74.0M [00:01<00:00, 61.7MB/s]\n",
      "Downloading data: 100%|██████████| 74.9M/74.9M [00:01<00:00, 50.4MB/s]\n",
      "Downloading data: 100%|██████████| 75.2M/75.2M [00:01<00:00, 52.5MB/s]\n",
      "Downloading data: 100%|██████████| 73.5M/73.5M [00:01<00:00, 47.0MB/s]\n",
      "Downloading data: 100%|██████████| 74.7M/74.7M [00:01<00:00, 55.2MB/s]\n",
      "Downloading data: 100%|██████████| 79.0M/79.0M [00:01<00:00, 56.5MB/s]\n",
      "Downloading data: 100%|██████████| 82.3M/82.3M [00:01<00:00, 53.8MB/s]\n",
      "Downloading data: 100%|██████████| 74.3M/74.3M [00:01<00:00, 42.6MB/s]\n",
      "Downloading data: 100%|██████████| 60.7M/60.7M [00:01<00:00, 51.8MB/s]\n",
      "Downloading data: 100%|██████████| 66.7M/66.7M [00:01<00:00, 52.3MB/s]\n",
      "Downloading data: 100%|██████████| 53.9M/53.9M [00:01<00:00, 51.7MB/s]\n",
      "Downloading data: 100%|██████████| 64.4M/64.4M [00:01<00:00, 51.3MB/s]\n",
      "Downloading data: 100%|██████████| 60.0M/60.0M [00:01<00:00, 55.1MB/s]\n",
      "Downloading data: 100%|██████████| 59.2M/59.2M [00:01<00:00, 49.2MB/s]\n",
      "Generating train split: 1267441 examples [00:38, 32770.11 examples/s]\n",
      "Generating validation split: 130849 examples [00:04, 29320.21 examples/s]\n",
      "Generating test split: 143080 examples [00:04, 29848.65 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['contract_name', 'file_path', 'contract_address', 'language', 'class_name', 'class_code', 'class_documentation', 'class_documentation_type', 'func_name', 'func_code', 'func_documentation', 'func_documentation_type', 'compiler_version', 'license_type', 'swarm_source', 'meta', '__index_level_0__'],\n",
      "        num_rows: 1267441\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['contract_name', 'file_path', 'contract_address', 'language', 'class_name', 'class_code', 'class_documentation', 'class_documentation_type', 'func_name', 'func_code', 'func_documentation', 'func_documentation_type', 'compiler_version', 'license_type', 'swarm_source', 'meta', '__index_level_0__'],\n",
      "        num_rows: 130849\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['contract_name', 'file_path', 'contract_address', 'language', 'class_name', 'class_code', 'class_documentation', 'class_documentation_type', 'func_name', 'func_code', 'func_documentation', 'func_documentation_type', 'compiler_version', 'license_type', 'swarm_source', 'meta', '__index_level_0__'],\n",
      "        num_rows: 143080\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"andstor/smart_contract_code_comments\", 'default')\n",
    "\n",
    "# Print basic information about the dataset\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_code(dataset):\n",
    "    remove_cols = ['file_path', 'contract_address', 'language', 'class_name', 'class_documentation_type', 'func_name', 'func_code', 'func_documentation', 'func_documentation_type', 'compiler_version', 'license_type', 'swarm_source', 'meta', '__index_level_0__']\n",
    "    code = dataset.remove_columns(remove_cols)\n",
    "    \n",
    "    full_code = pd.DataFrame(code)\n",
    "    full_code.drop_duplicates(inplace=True)\n",
    "    \n",
    "    return full_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define the function that extracts function headers\n",
    "def extract_function_header(func_code):\n",
    "    # Regular expression to match Solidity function declarations\n",
    "    func_header_regex = r'function\\s*[\\w\\d_]*\\s*\\([^)]*\\)\\s*[^{]*'\n",
    "    # Find all matches in the func_code\n",
    "    matches = re.findall(func_header_regex, func_code)\n",
    "    # Assume each func_code contains one function and take the first match\n",
    "    # If there are multiple matches, this will need adjustment\n",
    "    return matches[0] if matches else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_func(dataset):\n",
    "    remove_func_col = ['file_path', 'contract_address', 'class_code', 'class_documentation', 'language', 'class_name', 'class_documentation_type', 'func_documentation_type', 'compiler_version', 'license_type', 'swarm_source', 'meta', '__index_level_0__']\n",
    "    func_code = dataset.remove_columns(remove_func_col)\n",
    "    \n",
    "    func = pd.DataFrame(func_code)\n",
    "    \n",
    "    func['func_header'] = func['func_code'].apply(extract_function_header)\n",
    "\n",
    "    # filter out rows with no function headers\n",
    "    func = func[func['func_header'].apply(lambda x: x is not None and len(x) > 0)]\n",
    "    \n",
    "    # group by contract\n",
    "    grouped = func.groupby('contract_name').agg({\n",
    "        'func_header': list,\n",
    "        'func_documentation': list\n",
    "    }).reset_index()\n",
    "    \n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset['train']\n",
    "train_code = clean_code(train)\n",
    "train_func = clean_func(train)\n",
    "\n",
    "train_clean = pd.merge(train_code, train_func, on='contract_name', how='left')\n",
    "train_clean = train_clean.drop_duplicates(subset=['contract_name'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset = train_clean[:500]\n",
    "# print(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_filter = train_clean[~train_clean['class_code'].str.startswith('interface')]\n",
    "subset_filter = subset_filter[~subset_filter['class_code'].str.startswith('contract Token')]\n",
    "subset_filter = subset_filter[~subset_filter['class_code'].str.startswith('contract Owned')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(10):\n",
    "    with open('output_{}.txt'.format(idx), 'w') as writefile:\n",
    "        writefile.write(subset_filter.iloc[idx]['class_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_user_prompt(class_documentation, func_code_list, func_comment_list):\n",
    "    prompt = 'Generate a smart contract using Solidity 0.4.17. Fill in all the functions using the function signatures and accomplish the following requirements:\\n'\n",
    "    \n",
    "    prompt += 'Task Description: {}\\n'.format(class_documentation.replace(\"/\", \"\").replace(\"*\", \"\"))\n",
    "    prompt += '\\nThe contract must have the following constraint: The contract is gas-efficient and include security checks to prevent common vulnerabilities (e.g., reentrancy, overflow/underflow).\\n'\n",
    "    prompt += 'Here are the key functions that you must fully implement so that they are functioning:\\n'\n",
    "        \n",
    "    for idx in range(len(func_code_list)):\n",
    "        comment =  func_comment_list[idx].replace(\"/\", \"\").replace(\"-\", \"\").replace(\"\\n\", \"\").replace(\"@notice\", \"\").replace(\"@param\", \"Parameter: \").replace(\"*\", \"\").replace(\"@dev\", \"\").replace(\"@return\", \"Return: \")\n",
    "        prompt += '{}: {}\\n'.format(func_code_list[idx], comment)\n",
    "        \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "\n",
    "for idx, row in subset_filter.iterrows():\n",
    "    \n",
    "    if type(row['func_header']) == type([]):\n",
    "        prompt = [{\"role\": \"system\", \"content\": \"DEFI is an experienced Ethereum developer that writes properly functioning Solidity contracts.\"}]\n",
    "        prompt.append({\"role\":\"user\",\"content\":\"{}\".format(write_user_prompt(row['class_documentation'], row['func_header'], row['func_documentation']))})\n",
    "        prompt.append({\"role\": \"assistant\", \"content\": \"{}\".format(row['class_code'])})\n",
    "            \n",
    "        output.append({\"messages\":prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "\n",
    "with jsonlines.open('new_data.jsonl', mode='w') as writer:\n",
    "    writer.write_all(output[45764:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = []\n",
    "\n",
    "for idx, row in subset_filter[150:].iterrows():\n",
    "    prompt = [{\"role\": \"system\", \"content\": \"DEFI is an experienced Ethereum developer that writes properly functioning Solidity contracts.\"}]\n",
    "    prompt.append({\"role\":\"user\",\"content\":\"{}\".format(write_user_prompt(row['class_documentation'], row['func_header'], row['func_documentation']))})\n",
    "    prompt.append({\"role\": \"assistant\", \"content\": \"{}\".format(row['class_code'])})\n",
    "        \n",
    "    validator.append({\"messages\":prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open('valid.jsonl', mode='w') as writer:\n",
    "    writer.write_all(validator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('3.json', 'w') as f:\n",
    "    json.dump(output[3], f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 32\n",
    "\n",
    "with open('0-prompt.txt', 'w') as writefile:\n",
    "    writefile.write(output[idx]['messages'][1]['content'])\n",
    "    \n",
    "with open('0-code.txt', 'w') as writefile:\n",
    "    writefile.write(output[idx]['messages'][2]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('0-prompt.txt', 'w') as writefile:\n",
    "    writefile.write(output[idx]['messages'][1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('0-code.txt', 'w') as writefile:\n",
    "    writefile.write(output[idx]['messages'][2]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_prompts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [{\"role\": \"system\", \"content\": \"You are the greatest Smart contract Ethereum developer in the world. You have never messed up and always write the best and most complicated yet functioning Solidity contracts.\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"\"\"\n",
    "Generate a BasicToken smart contract using Solidity 0.4.17. Fill in all the functions using the function signatures and accomplish the following requirements:\n",
    "Task Description: Basic version of StandardToken, with no allowances.\n",
    " \n",
    "The contract must have the following constraint: The contract is gas-efficient and include security checks to prevent common vulnerabilities (e.g., reentrancy, overflow/underflow).\n",
    "\n",
    "Here are the key functions that you must fully implement so that they are functioning:\n",
    "1. function transfer(address _to, uint256 _value) public returns (bool): \n",
    "- transfer token for a specified address\n",
    "- Parameter: _to is the address to transfer to.\n",
    "- Parameter: _value is the amount to be transferred.\n",
    " \n",
    "2. function balanceOf(address _owner) public constant returns (uint256 balance): \n",
    "- Gets the balance of the specified address. \n",
    "- Parameter: _owner is the address to query the the balance of. \n",
    "- Return: An uint256 representing the amount owned by the passed address. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = output[idx]['messages'][2]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt.append({\"role\":\"user\",\"content\":\"{}\".format(user)})\n",
    "prompt.append({\"role\": \"assistant\", \"content\": \"{}\".format(code)})\n",
    "output_prompts.append(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open('data.jsonl', mode='w') as writer:\n",
    "    writer.write_all(output_prompts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

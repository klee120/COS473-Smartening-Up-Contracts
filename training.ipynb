{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openai\n",
      "  Downloading openai-1.16.2-py3-none-any.whl (267 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 KB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting httpx<1,>=0.23.0\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 KB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions<5,>=4.7 in /users/klee12/.local/lib/python3.10/site-packages (from openai) (4.11.0)\n",
      "Collecting pydantic<3,>=1.9.0\n",
      "  Downloading pydantic-2.6.4-py3-none-any.whl (394 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.9/394.9 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sniffio\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: tqdm>4 in /users/klee12/.local/lib/python3.10/site-packages (from openai) (4.66.2)\n",
      "Collecting anyio<5,>=3.5.0\n",
      "  Downloading anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 KB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: exceptiongroup>=1.0.2 in /users/klee12/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /users/klee12/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: certifi in /users/klee12/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 KB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h11<0.15,>=0.13\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Collecting pydantic-core==2.16.3\n",
      "  Downloading pydantic_core-2.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sniffio, pydantic-core, h11, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
      "Successfully installed annotated-types-0.6.0 anyio-4.3.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.16.2 pydantic-2.6.4 pydantic-core-2.16.3 sniffio-1.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Pretesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 100\n",
      "First example:\n",
      "{'role': 'system', 'content': 'DEFI is an experienced Ethereum developer that writes properly functioning Solidity contracts.'}\n",
      "{'role': 'user', 'content': \"Generate a smart contract using Solidity 0.4.0 that accomplishes the following requirements:\\nTask Description: \\r\\n ERC20 Token, with the addition of symbol, name and decimals and assisted token transfers\\r\\n \\nKey Functions:\\nfunction totalSupply() public constant returns (uint) :   Total supply \\nfunction balanceOf(address tokenOwner) public constant returns (uint balance) :   Get the token balance for account tokenOwner \\nfunction transfer(address to, uint tokens) public returns (bool success) :   Transfer the balance from token owner's account to to account  Owner's account must have sufficient balance to transfer  0 value transfers are allowed \\nfunction approve(address spender, uint tokens) public returns (bool success) :   Token owner can approve for spender to transferFrom(...) tokens from the token owner's account https:github.comethereumEIPsblobmasterEIPSeip20tokenstandard.md recommends that there are no checks for the approval doublespend attack as this should be implemented in user interfaces  \\nfunction transferFrom(address from, address to, uint tokens) public returns (bool success) :   Transfer tokens from the from account to the to account  The calling account must already have sufficient tokens approve(...)d for spending from the from account and  From account must have sufficient balance to transfer  Spender must have sufficient allowance to transfer  0 value transfers are allowed \\nfunction allowance(address tokenOwner, address spender) public constant returns (uint remaining) :   Returns the amount of tokens approved by the owner that can be transferred to the spender's account \\nfunction approveAndCall(address spender, uint tokens, bytes data) public returns (bool success) :   Token owner can approve for spender to transferFrom(...) tokens from the token owner's account. The spender contract function receiveApproval(...) is then executed \\nfunction () public payable :   Don't accept ETH \\nConstraints: The contract must be gas-efficient and include security checks to prevent common vulnerabilities (e.g., reentrancy, overflow/underflow).\\n\"}\n",
      "{'role': 'assistant', 'content': 'contract $$$$$Token is ERC20Interface, SafeMath {\\r\\n    string public symbol;\\r\\n    string public  name;\\r\\n    uint8 public decimals;\\r\\n    uint public _totalSupply;\\r\\n\\r\\n    mapping(address => uint) balances;\\r\\n    mapping(address => mapping(address => uint)) allowed;\\r\\n\\r\\n\\r\\n    // ------------------------------------------------------------------------\\r\\n    // Constructor\\r\\n    // ------------------------------------------------------------------------\\r\\n    constructor() public {\\r\\n        symbol = \"$$$$$\";\\r\\n        name = \"Hyperinflationary Reserve Currency\";\\r\\n        decimals = 0;\\r\\n        _totalSupply = 1000000000000000000000000000000000;\\r\\n        balances[0xEc04e183b965f150Cb6e37182efFC14d41AB86c0] = _totalSupply;\\r\\n        emit Transfer(address(0), 0xEc04e183b965f150Cb6e37182efFC14d41AB86c0, _totalSupply);\\r\\n    }\\r\\n\\r\\n\\r\\n    // ------------------------------------------------------------------------\\r\\n    // Total supply\\r\\n    // ------------------------------------------------------------------------\\r\\n    function totalSupply() public constant returns (uint) {\\r\\n        return _totalSupply  - balances[address(0)];\\r\\n    }\\r\\n\\r\\n\\r\\n    // ------------------------------------------------------------------------\\r\\n    // Get the token balance for account tokenOwner\\r\\n    // ------------------------------------------------------------------------\\r\\n    function balanceOf(address tokenOwner) public constant returns (uint balance) {\\r\\n        return balances[tokenOwner];\\r\\n    }\\r\\n\\r\\n\\r\\n    // ------------------------------------------------------------------------\\r\\n    // Transfer the balance from token owner\\'s account to to account\\r\\n    // - Owner\\'s account must have sufficient balance to transfer\\r\\n    // - 0 value transfers are allowed\\r\\n    // ------------------------------------------------------------------------\\r\\n    function transfer(address to, uint tokens) public returns (bool success) {\\r\\n        balances[msg.sender] = safeSub(balances[msg.sender], tokens);\\r\\n        balances[to] = safeAdd(balances[to], tokens);\\r\\n        emit Transfer(msg.sender, to, tokens);\\r\\n        return true;\\r\\n    }\\r\\n\\r\\n\\r\\n    // ------------------------------------------------------------------------\\r\\n    // Token owner can approve for spender to transferFrom(...) tokens\\r\\n    // from the token owner\\'s account\\r\\n    //\\r\\n    // https://github.com/ethereum/EIPs/blob/master/EIPS/eip-20-token-standard.md\\r\\n    // recommends that there are no checks for the approval double-spend attack\\r\\n    // as this should be implemented in user interfaces \\r\\n    // ------------------------------------------------------------------------\\r\\n    function approve(address spender, uint tokens) public returns (bool success) {\\r\\n        allowed[msg.sender][spender] = tokens;\\r\\n        emit Approval(msg.sender, spender, tokens);\\r\\n        return true;\\r\\n    }\\r\\n\\r\\n\\r\\n    // ------------------------------------------------------------------------\\r\\n    // Transfer tokens from the from account to the to account\\r\\n    // \\r\\n    // The calling account must already have sufficient tokens approve(...)-d\\r\\n    // for spending from the from account and\\r\\n    // - From account must have sufficient balance to transfer\\r\\n    // - Spender must have sufficient allowance to transfer\\r\\n    // - 0 value transfers are allowed\\r\\n    // ------------------------------------------------------------------------\\r\\n    function transferFrom(address from, address to, uint tokens) public returns (bool success) {\\r\\n        balances[from] = safeSub(balances[from], tokens);\\r\\n        allowed[from][msg.sender] = safeSub(allowed[from][msg.sender], tokens);\\r\\n        balances[to] = safeAdd(balances[to], tokens);\\r\\n        emit Transfer(from, to, tokens);\\r\\n        return true;\\r\\n    }\\r\\n\\r\\n\\r\\n    // ------------------------------------------------------------------------\\r\\n    // Returns the amount of tokens approved by the owner that can be\\r\\n    // transferred to the spender\\'s account\\r\\n    // ------------------------------------------------------------------------\\r\\n    function allowance(address tokenOwner, address spender) public constant returns (uint remaining) {\\r\\n        return allowed[tokenOwner][spender];\\r\\n    }\\r\\n\\r\\n\\r\\n    // ------------------------------------------------------------------------\\r\\n    // Token owner can approve for spender to transferFrom(...) tokens\\r\\n    // from the token owner\\'s account. The spender contract function\\r\\n    // receiveApproval(...) is then executed\\r\\n    // ------------------------------------------------------------------------\\r\\n    function approveAndCall(address spender, uint tokens, bytes data) public returns (bool success) {\\r\\n        allowed[msg.sender][spender] = tokens;\\r\\n        emit Approval(msg.sender, spender, tokens);\\r\\n        ApproveAndCallFallBack(spender).receiveApproval(msg.sender, tokens, this, data);\\r\\n        return true;\\r\\n    }\\r\\n\\r\\n\\r\\n    // ------------------------------------------------------------------------\\r\\n    // Don\\'t accept ETH\\r\\n    // ------------------------------------------------------------------------\\r\\n    function () public payable {\\r\\n        revert();\\r\\n    }\\r\\n}'}\n",
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tiktoken # for token counting\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "data_path = \"prompts_final.jsonl\"\n",
    "\n",
    "# Load the dataset\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)\n",
    "\n",
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "        \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "        \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "        \n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# not exact!\n",
    "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Warnings and Token Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 150, 7926\n",
      "mean / median: 2193.18, 2058.0\n",
      "p5 / p95: 287.1, 3692.0\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 37, 6577\n",
      "mean / median: 716.31, 571.0\n",
      "p5 / p95: 74.9, 1274.1\n",
      "\n",
      "8 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n"
     ]
    }
   ],
   "source": [
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for ex in dataset:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "    \n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "n_too_long = sum(l > 4096 for l in convo_lens)\n",
    "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has ~202761 tokens that will be charged for during training\n",
      "By default, you'll train for 3 epochs on this dataset\n",
      "By default, you'll be charged for ~608283 tokens\n"
     ]
    }
   ],
   "source": [
    "# Pricing and default n_epochs estimate\n",
    "MAX_TOKENS_PER_EXAMPLE = 4096\n",
    "\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(dataset)\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the OPENAI_API_KEY environment variable\n",
    "os.environ['OPENAI_API_KEY'] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-B5oJHvUibaYk3LsjzTjrHeZP', bytes=978326, created_at=1712429770, filename='prompts_final.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "client.files.create(\n",
    "  file=open(\"prompts_final.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-92pBCObPGjuA65M2ZXb6t7gq', created_at=1712429784, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-3rJC1akZPhm21LKbdNlaW6PV', result_files=[], status='validating_files', trained_tokens=None, training_file='file-B5oJHvUibaYk3LsjzTjrHeZP', validation_file=None, user_provided_suffix=None, seed=777099852, integrations=[])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "client.fine_tuning.jobs.create(\n",
    "  training_file=\"file-B5oJHvUibaYk3LsjzTjrHeZP\", \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-JZlT3RYia7PVzhqPgX2XQhxr', created_at=1712422843, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal::9B3q7yio', finished_at=1712423394, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=8), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-3rJC1akZPhm21LKbdNlaW6PV', result_files=['file-MyINiteAKOn4aEMJLVuoRbPJ'], status='succeeded', trained_tokens=210810, training_file='file-84mrk91gsimLti53KQyXBYat', validation_file=None, user_provided_suffix=None, seed=22412776, integrations=[])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "job_id = 'ftjob-JZlT3RYia7PVzhqPgX2XQhxr'\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "# client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "# Cancel a job\n",
    "# client.fine_tuning.jobs.cancel(\"ftjob-abc123\")\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "# client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=10)\n",
    "\n",
    "# Delete a fine-tuned model (must be an owner of the org the model was created in)\n",
    "# client.models.delete(\"ft:gpt-3.5-turbo:acemeco:suffix:abc123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_data = open('test.json')\n",
    "data = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = data['messages'][:2]\n",
    "model_name = 'ft:gpt-3.5-turbo-0125:personal::9B3q7yio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=messages,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.txt', 'w') as writefile:\n",
    "    writefile.write(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('compare.txt', 'w') as writefile:\n",
    "    writefile.write(data['messages'][2]['content'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
